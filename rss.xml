<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[Paul-Louis Pröve]]></title>
        <description><![CDATA[Paul-Louis Pröve]]></description>
        <link>http://plpp.de/</link>
        <generator>The Grid</generator>
        <lastBuildDate>Sat, 21 Oct 2017 08:11:12 GMT</lastBuildDate>
        <atom:link href="http://plpp.de/rss.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Sat, 21 Oct 2017 08:11:11 GMT</pubDate>
        <item>
            <title><![CDATA[How old am I?]]></title>
            <description><![CDATA[<h1>How old am I?</h1>,<h3>Age Assessment using 3D Knee MRIs and Convolutional Neural&nbsp;Networks</h3>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/82062838-f452-4e9b-85e5-d8718f2a454a.gif">,<p>Can you guess how old the person is behind this knee MRI? I give you a hint. It’s a recording of a German male between the age of 14 and 21 years. No idea? I like to imagine that this is how a neural network sees the world before it has been trained. It has absolutely no clue. So, let me train you.</p>,<p>Determining the chronological age of a person is a complex procedure when dealing with people who lack legal documentation. This is often the case in asylum applications or criminal proceedings. Children and adults are processed differently under the law, but we simply don’t have an accurate way of determining how old somebody is. The best approaches we use today are based on X-ray, which is an invasive imaging technique that exposes the patient to ionizing radiation. That’s why many European countries only allow these recordings as part of a judicial order. Some other methods include personal interviews to determine psychological and physiological traits, but they are time-consuming and also subjective. That’s why there is a high demand for an automated and noninvasive method for accurately determining the age of a person.</p>,<p>As part of a study for the German Research Foundation (DFG), I was introduced to a data set of 3D MRIs showing the right knee of German males. The Femur in the upper half of the images is the thighbone, and the Tibia right below is the shinbone. Towards the back of the recording, you can see another bone popping up in the lower left corner — the Fibula. If you look even closer, you can spot dark horizontal lines in the bones that almost look like cracks. These are called growth plates because it’s where your bones realize longitudinal growth. They consist of cartilage which is why they can be seen in MRI recordings. Once you stop growing, these regions will slowly start to close up until they are not visible anymore.</p>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/30725017-244d-4872-ba71-9482676a3a2f.jpg">,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/a5a335ef-7566-450f-b1a2-8394be17270c.jpg">,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/32c9b154-26fe-430b-86a3-e88bf986d916.jpg">,<p>We used knee recordings for this study because the visible growth plates are known to close around the border to adulthood. Other studies use MRIs or X-rays of hands, where the growth plates are known to close earlier. In the images above you can see how the width of the dark horizontal gap correlates to the age of a person.</p>,<p>The individuals we recorded were between the age of 14 and 21 years.If we predicted the mean age of 17.5 for every person, we would never be off more than 3.5 years. In fact, we would be off by just 1.2 years on average because the data was normally distributed. This was the original baseline I tried to beat. I like to think of the baseline as the smartest stupid estimate you can make. A model that only predicts an age of 17.5 wouldshowa mean difference of 1.2 years. It would also be completely useless.</p>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/e26107e8-6b83-4ac9-98b9-38288fac91cd.png">,<p>One of the first things you normally try in deep learning is a plug-and-play approach using a pre-trained architecture. This can often get you pretty far even if the original model was trained on a very different data set. I took my favorite transfer learning architecture VGG16 and weights it learned on ImageNet. However, I quickly understood that this wouldn’t get me anywhere because the model didn’t converge. I tried all kinds of other bells and whistles like far simpler architectures, special training procedures or turning the regression into a classification problem. Nothing worked.</p>,<p>So, I took a step back. Either the data shows no correlating features to the age or the problem is simply too complex for the size of my data set. Since the data consisted of only 145 images, the second possibility didn’t seem so far off. In a situation like this you can do two things:</p>,<ul><li>get more training data</li><li>reduce the complexity of the problem</li></ul>,<p>In a perfect world the first option is definitely more desirable, but especially in the medical field it’s sometimes not an option. We’re under very strict privacy laws when it comes to medical data, which is a good thing unless you’re working on a problem like this. So I decided to reduce the data complexity instead.</p>,<p>Lucky me, a diligent person working on the same project already labeled half of the data set with segmentation maps of the bones. It took him roughly 2 hours per sample using a semi automated approach based on region growing. Having these 76 masks, I set up a workflow that segmented the bones in 3D MRIs of human knees. I tried both 2D and 3D CNN architectures, but the 2D version showed more accurate results and was also much faster to train.</p>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/44307af0-48a4-4cf1-aa45-463339c4fdc1.png">,<p>In the end, I got to <strong>98.0% DSC </strong>using a small variant of U-Net with a constant number of 32 output channels for every convolution. Things became a little problematic with the Fibula, the smallest bone, which is why I decided to train three separate models. I also tried a whole bunch of other things that you can read about in my thesis, but for now, I want to keep it at that.</p>,<p>By the way, aren’t you surprised that this worked so well? I surely was at first. Think about it. I wasn’t able to train a regressor on 145 samples, but a more complex segmentation on 76 samples worked flawlessly. Well, it turns out a segmentation can be seen as a classification for every pixel. That means for each sample I had <em>width*height </em>information to back-propagate through the network. That’s a lot more than one numeric value resulting from a simple regression.</p>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/c60a9acd-446e-40fb-9915-7e77458afc44.png">,<p>With the masks applied to the input data, I got rid of all the non-bone tissue I didn’t care about and was able to focus more clearly on the growth plates. I came back to the original problem but noticed quickly that it still wouldn’t work. Only after taking the contracting side of my segmentation architecture and using it as a pre-trained model was I able to beat the baseline. This idea will not make the model converge every time, but when it does its predictions are stable.</p>,<p>Because this network used 2D slices out of each volumetric image I now had multiple predictions for each MRI. On average I was wrong by 0.64 (±0.48) years. Apparently, that’s already a very good result beating previous carpal MRI studies and an algorithm called boneXpert that uses X-rays.</p>,<p>I analysed the different predictions for each 2D image and noticed that inner slices resulted in a higher accuracy. I ran experiments with weighted averages and discarding outer slices. Both concepts improved the results from before, but another approach yielded even higher accuracy. I set up aRandom Forest Regressorthat would take a vector of multiple age predictions and output a single estimate for each 3D MRI. This got me to a mean difference of<strong>0.48 (±0.32) years</strong>on the test set. In other words, this workflow let’s me assess the age of caucasian male 14 to 21 year olds with an average error of half a year.</p>,<p>This project became my bachelor thesis. I’m planning on open sourcing the code and paper, so anyone can use it for future work. For now, I have to wait what the committee thinks about it before I release anything. I find it incredible that somebody like me with no medical background can contribute to current research using AI algorithms. It’s what amazes me about this field of computer science and I hope to continue working on fascinating projects like this one in the future.</p>]]></description>
            <link>http://plpp.de/how-old-am-i-towards-data-science-medium/index.html</link>
            <guid isPermaLink="false">44116bd9-9c2e-48bc-9814-320dd46f2fdb</guid>
            <pubDate>Sun, 10 Sep 2017 19:27:35 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[An Introduction to different Types of Convolutions]]></title>
            <description><![CDATA[<article><img src="https://imgflo.herokuapp.com/graph/2b2431f8e7ba7b0/038d1ae60d2ad79c7029fffd9f62123e/noop.gif?input=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F1200%2F1*1okwhewf5KCtIPaFib4XaA.gif"><h1>An Introduction to different Types of Convolutions</h1><p>Let me give you a quick overview of different types of convolutions and what their benefits are. For the sake of simplicity I&apos;m focussing on 2D convolutions only.</p></article>]]></description>
            <link>https://medium.com/@pietz/types-of-convolutions-in-deep-learning-717013397f4d</link>
            <guid isPermaLink="false">3957a246-1600-4e91-bbc0-284ecf6b7d68</guid>
            <pubDate>Sat, 22 Jul 2017 21:09:20 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Spoken Language Recognition]]></title>
            <description><![CDATA[<h1>Spoken Language Recognition</h1>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/d404f00f-cca8-429a-98ea-e7a949ed2001.jpg">,<p>I trained a convolutional neural network to classify audio files of voice recordings into the languages that were spoken. The dataset I used contained 66.000 files across 176 languages. I found it on <a href="https://goo.gl/G5XBJl" title="TopCoder Competition">TopCoder</a>. I liked the idea behind this problem, because it's very hard for humans to do. It's interesting to see that CNNs perform well on problems where intuition doesn't get you anywhere.</p>]]></description>
            <link>http://plpp.de/spoken-language-recognition/index.html</link>
            <guid isPermaLink="false">18024fcb-a3fc-4d2b-aaf8-03f1c6262c3a</guid>
            <pubDate>Tue, 23 May 2017 21:32:41 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Password Attacks Paper]]></title>
            <description><![CDATA[<h1>Password Attacks Paper</h1>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/e38cd300-70ea-449b-b976-2ced9c71bdcd.jpg">,<p>Password attacks are at the edge of accessing someones secrets. By learning to judge the strength of a password and by understanding how hackers execute attacks, users can make better estimations on how safe they are.</p>]]></description>
            <link>http://plpp.de/password-attacks-paper/index.html</link>
            <guid isPermaLink="false">be4c6567-db2e-41f6-bf1c-c7e24d9c429a</guid>
            <pubDate>Wed, 24 May 2017 07:36:11 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Ethereum based Insurance]]></title>
            <description><![CDATA[<h1>Ethereum based Insurance</h1>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/5df8c2a1-5a71-431c-bb93-bdfdd20d7367.jpg">,<p>Secureum is a working prototype of an anonymous insurance service. The idea was to create a simple and secure way to protect yourself against flight delays or extreme weather conditions. We used Ethereum based smart contracts to automate the validation of payouts and prevent the leakage of personal information. All you need is an Ethereum Wallet ID and 20 seconds of your time to go through a full insurance process. A working version of the service is currently not online.</p>]]></description>
            <link>http://plpp.de/ethereum-based-insurance/index.html</link>
            <guid isPermaLink="false">86a6de17-875f-4cb9-9edf-49fecba1d407</guid>
            <pubDate>Wed, 24 May 2017 13:18:13 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[KalahaGo]]></title>
            <description><![CDATA[<h1>KalahaGo</h1>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/0272ffe3-b1db-4a42-9671-10bb10eabcdf.jpg">,<p>KalahaGo is a game I wrote as an university project. It's based on the popular board game Kalaha, which is also often referred to as Mancala. It includes an AI opponent that is a lot better than me and features a colorful UI with several settings that can be tweaked.</p>]]></description>
            <link>http://plpp.de/kalahago/index.html</link>
            <guid isPermaLink="false">772d2acc-047e-48f1-a1d3-d165e3677ef4</guid>
            <pubDate>Fri, 26 Aug 2016 16:22:28 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[FH Wedel Skripte]]></title>
            <description><![CDATA[<h1>FH Wedel Skripte</h1>,<img src="https://the-grid-user-content.s3-us-west-2.amazonaws.com/3e59f748-ccf0-4802-a8ae-01cae04c466f.png">,<p>Die folgenden Links führen zu meinen persönlichen Lernunterlagen verschiedener Vorlesungen an der <strong>FH Wedel</strong>. Hinter jedem Link ist gekennzeichnet, was meine Einschätzung der Qualität und Vollständigkeit ist. Ich hoffe jedem ist klar, dass auch bei 3 Sternen Fehler enthalten sein werden. Jeder darf die Dokumente kommentieren und Korrekturen einreichen.</p>]]></description>
            <link>http://plpp.de/fh-wedel-skripte/index.html</link>
            <guid isPermaLink="false">8ad288a4-5951-4df3-9810-1f34bc9bd5dd</guid>
            <pubDate>Sat, 05 Aug 2017 11:19:07 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Squeeze-and-Excitation Networks - Towards Data Science - Medium]]></title>
            <description><![CDATA[<article><h1>Squeeze-and-Excitation Networks - Towards Data Science - Medium</h1><p>Setting a new state of the art on ImageNet Squeeze-and-Excitation Networks ( SENets) introduce a building block for CNNs that improves channel interdependencies at almost no computational cost. They were used at this years ImageNet competition and helped to improve the result from last year by 25%.</p><img src="https://cdn-images-1.medium.com/max/1200/1*bmObF5Tibc58iE9iOu327w.png"></article>]]></description>
            <link>https://medium.com/towards-data-science/squeeze-and-excitation-networks-9ef5e71eacd7</link>
            <guid isPermaLink="false">a4da39df-fad9-4ac2-9660-0ae37e43e6c2</guid>
            <pubDate>Sat, 21 Oct 2017 08:11:10 GMT</pubDate>
        </item>
    </channel>
</rss>